{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net with Partial Convolution\n",
    "----\n",
    "Based on: https://github.com/MathiasGruber/PConv-Keras/blob/master/notebooks/Step3%20-%20UNet%20Architecture.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from mask_generator import *\n",
    "from partialconv2d import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, use_batch_norm=True):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.pconv = PartialConv2d(in_channels, out_channels, kernel_size=kernel_size, stride=(2,2))\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_batch_norm else None\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # needed to save the output image for later skip connection\n",
    "        self.out_image = None\n",
    "        \n",
    "    def forward(self, in_image, in_mask):\n",
    "        self.out_image = self.pconv(in_image, in_mask)\n",
    "        if self.bn is not None:\n",
    "            self.out_image = self.bn(self.out_image)\n",
    "        self.out_image = self.relu(self.out_image)\n",
    "        \n",
    "        return self.out_image\n",
    "    \n",
    "    def get_mask_output(self):\n",
    "        return self.pconv.mask_out\n",
    "    \n",
    "    def get_output_shape(self, height, width, batch=1):\n",
    "        img = torch.zeros(batch, self.pconv.in_channels, height, width)\n",
    "        mask = torch.zeros(batch, self.pconv.in_channels, height, width)\n",
    "        y = self.forward(img, mask)\n",
    "        return y.size(), y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eb = EncoderBlock(512, 512, 3).to('cuda')\n",
    "# eb.get_output_shape(64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, concat_channels, kernel_size, use_batch_norm=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.concat_channels = concat_channels\n",
    "        \n",
    "        self.upsampling_img = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.upsampling_mask = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.pconv = PartialConv2d(\n",
    "            self.in_channels + self.concat_channels, \n",
    "            out_channels, kernel_size=kernel_size, stride=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_batch_norm else None\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        \n",
    "    def get_mask_output(self):\n",
    "        return self.pconv.mask_out\n",
    "        \n",
    "    def forward(self, in_image, in_mask, skip_img, skip_mask, verbose=False):\n",
    "\n",
    "        # upsampling\n",
    "        up_img = self.upsampling_img(in_image)\n",
    "        up_mask = self.upsampling_mask(in_mask)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"input {in_image.size()} upsampled into {up_img.size()} + skip_img {skip_img.size()}\")\n",
    "            print(f\"mask {in_mask.size()} upsampled into {up_mask.size()} + skip_mask {skip_mask.size()}\")\n",
    "        \n",
    "        # partial convolution from the concatenated images & masks\n",
    "        out_image = self.pconv(\n",
    "            torch.cat([skip_img, up_img], dim=1),\n",
    "            torch.cat([skip_mask, up_mask], dim=1)\n",
    "        )\n",
    "        \n",
    "        # and the rest\n",
    "        if self.bn is not None:\n",
    "            out_image = self.bn(out_image)\n",
    "        out_image = self.relu(out_image)\n",
    "        \n",
    "        return out_image\n",
    "        \n",
    "    def get_output_shape(self, height, width, batch=1):\n",
    "        x = torch.zeros(batch, self.in_channels, height, width)\n",
    "        y = torch.zeros(batch, self.in_channels, height, width)\n",
    "        \n",
    "        x_cat = torch.zeros(batch, self.concat_channels, 2*height, 2*width)\n",
    "        y_cat = torch.zeros(batch, self.concat_channels, 2*height, 2*width)\n",
    "        \n",
    "        z = self.forward(x,y,x_cat,y_cat)\n",
    "        \n",
    "        return z.size(), z.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DecoderBlock(512, 256, 256, 3).to('cuda')\n",
    "# print(f\"Output shape: {db.get_output_shape(32, 32)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialUNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super(PartialUNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.encoders = [\n",
    "            EncoderBlock(\n",
    "                c_in, c_out, kernel_size=(ks, ks), use_batch_norm=bn\n",
    "            ) for (c_in, c_out, ks, bn) in [\n",
    "                (in_channels, 64, 7, False),\n",
    "                (64, 128, 5, True),\n",
    "                (128, 256, 5, True),\n",
    "                (256, 512, 3, True),\n",
    "                (512, 512, 3, True),\n",
    "                (512, 512, 3, True),\n",
    "                (512, 512, 3, True),\n",
    "                (512, 512, 3, True)\n",
    "            ]\n",
    "        ]\n",
    "        \n",
    "        self.decoders = [DecoderBlock(\n",
    "            c_in, c_out, c_cat, kernel_size=ks, use_batch_norm=bn\n",
    "        ) for (c_in, c_out, c_cat, ks, bn) in [\n",
    "            (512, 512, 512, 3, True),\n",
    "            (512, 512, 512, 3, True),\n",
    "            (512, 512, 512, 3, True),\n",
    "            (512, 512, 512, 3, True),\n",
    "            (512, 256, 256, 3, True),\n",
    "            (256, 128, 128, 3, True),\n",
    "            (128, 64, 64, 3, True),\n",
    "            (64, 3, 3, 3, False)\n",
    "        ]]\n",
    "        \n",
    "        # last layer\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=1, stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_image, in_mask=None):\n",
    "        \n",
    "        # create in_mask if it is None (used in testing)\n",
    "        if in_mask is None:\n",
    "            in_mask = torch.ones_like(in_image).to(in_image)\n",
    "        \n",
    "        # encoding\n",
    "        out_image = self.encoders[0](in_image, in_mask)\n",
    "        for i in range(len(self.encoders)-1):\n",
    "            out_image = self.encoders[i+1](out_image, self.encoders[i].get_mask_output())\n",
    "            \n",
    "        # decoding\n",
    "        for i in range(len(self.decoders)-1):\n",
    "            j = (i-2*i)-1\n",
    "            out_image = self.decoders[i](\n",
    "                out_image, self.encoders[j].get_mask_output(),\n",
    "                self.encoders[j-1].out_image, self.encoders[j-1].get_mask_output()\n",
    "            )\n",
    "            \n",
    "        # the last one, concate with the input image & mask\n",
    "        if in_mask.shape[1]==1:\n",
    "            in_mask = in_mask.repeat(1, in_image.shape[1], 1, 1)\n",
    "\n",
    "        out_image = self.decoders[-1](\n",
    "            out_image, self.encoders[0].get_mask_output(),\n",
    "            in_image, in_mask\n",
    "        )\n",
    "            \n",
    "        # last layer\n",
    "        self.output_layer.to(in_image)\n",
    "        out_image = self.output_layer(out_image)\n",
    "\n",
    "        return out_image\n",
    "    \n",
    "    def get_output_shape(self, height, width, batch=1):\n",
    "        x = torch.zeros(batch, self.in_channels, height, width)\n",
    "        m = torch.zeros(batch, 1, height, width)\n",
    "        y = self.forward(x, m)\n",
    "        return y.size(), y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punet = PartialUNet(3).to('cuda')\n",
    "# print(f\"len(encoders) = {len(punet.encoders)}\")\n",
    "# print(f\"len(decoders) = {len(punet.decoders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punet.get_output_shape(512, 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
